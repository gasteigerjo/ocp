# -*- coding: utf-8 -*-
"""LOGML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_3Wjo4lScWzH08njJsVYe1XEDUWBwXhR

Following the tutorials at: 
* https://colab.research.google.com/github/Open-Catalyst-Project/ocp/blob/master/tutorials/OCP_Tutorial.ipynb#scrollTo=ruspSf6CQIk4
* https://github.com/Open-Catalyst-Project/ocp/blob/main/tutorials/train_s2ef_example.ipynb

# Prerequisites
"""

import torch
import os
import logging

from scripts.download_data import get_data
from ocpmodels.trainers import ForcesTrainer
from ocpmodels import models
from ocpmodels.common import logger
from ocpmodels.common.utils import setup_logging, load_config
from ocpmodels.common.flags import flags

# should this be called after knowing the log directory w
setup_logging()

"""# Teacher model

Setting up the teacher model's config
"""

teacher_config, _, _ = load_config('configs/s2ef/2M/gemnet/gemnet-oc.yml')
teacher_config

teacher_dataset = None  # define destilling data

"""e.g. if we use 200k data as distilling data"""

# Commented out IPython magic to ensure Python compatibility.
# %run -i 'scripts/download_data.py' --task s2ef --split "200k" --get-edges
dataset = [{'src': '/content/ocp/data/s2ef/200k/train', 'normalize_labels': False}]

"""Downloading the pretrained GemNet_OC model


"""

checkpoint_path = "/content/ocp/gemnet_oc_base_s2ef_2M.pt"

teacher_pretrained_trainer = ForcesTrainer(
    task=teacher_config['task'],
    model=teacher_config['model'],
    dataset=dataset,  # TODO: change to distilling data
    optimizer=teacher_config['optim'],
    identifier="S2EF-gemnet-t",
)

teacher_pretrained_trainer.load_checkpoint(checkpoint_path=checkpoint_path)

"""## Student model"""

student_config, _, _ = load_config('configs/s2ef/all/painn/painn_h512.yml')
student_config

student_trainer = ForcesTrainer(
    task=student_config['task'],
    model=student_config['model'],
    dataset=dataset,
    optimizer=student_config['optim'],
    identifier="S2EF-painn",
)

"""## Knowledge Distilling

extend train function from https://github.com/Open-Catalyst-Project/ocp/blob/bfd2d62758896ee38132636c03fdce43df2e2fe7/ocpmodels/trainers/forces_trainer.py#L325 to include KD loss
"""

from ocpmodels.common import distutils

def train(self, disable_eval_tqdm=False, kd_labels=None, kd_alpha=0.5, kd_loss_fn=torch.nn.L1Loss):
    eval_every = self.config["optim"].get(
        "eval_every", len(self.train_loader)
    )
    checkpoint_every = self.config["optim"].get(
        "checkpoint_every", eval_every
    )
    primary_metric = self.config["task"].get(
        "primary_metric", self.evaluator.task_primary_metric[self.name]
    )
    if (
        not hasattr(self, "primary_metric")
        or self.primary_metric != primary_metric
    ):
        self.best_val_metric = 1e9 if "mae" in primary_metric else -1.0
    else:
        primary_metric = self.primary_metric
    self.metrics = {}

    # Calculate start_epoch from step instead of loading the epoch number
    # to prevent inconsistencies due to different batch size in checkpoint.
    start_epoch = self.step // len(self.train_loader)

    for epoch_int in range(
        start_epoch, self.config["optim"]["max_epochs"]
    ):
        self.train_sampler.set_epoch(epoch_int)
        skip_steps = self.step % len(self.train_loader)
        train_loader_iter = iter(self.train_loader)

        for i in range(skip_steps, len(self.train_loader)):
            self.epoch = epoch_int + (i + 1) / len(self.train_loader)
            self.step = epoch_int * len(self.train_loader) + i + 1
            self.model.train()

            # Get a batch.
            batch = next(train_loader_iter)

            # Forward, loss, backward.
            with torch.cuda.amp.autocast(enabled=self.scaler is not None):
                out = self._forward(batch)
                loss = self._compute_loss(out, batch)

                # KD LOSS
                if kd_labels:
                  distillation_loss = kd_loss_fn(kd_labels, out)

                  loss = kd_alpha * loss + (1 - kd_alpha) * distillation_loss

            loss = self.scaler.scale(loss) if self.scaler else loss
            self._backward(loss)
            scale = self.scaler.get_scale() if self.scaler else 1.0

            # Compute metrics.
            self.metrics = self._compute_metrics(
                out,
                batch,
                self.evaluator,
                self.metrics,
            )
            self.metrics = self.evaluator.update(
                "loss", loss.item() / scale, self.metrics
            )

            # Log metrics.
            log_dict = {k: self.metrics[k]["metric"] for k in self.metrics}
            log_dict.update(
                {
                    "lr": self.scheduler.get_lr(),
                    "epoch": self.epoch,
                    "step": self.step,
                }
            )
            if (
                self.step % self.config["cmd"]["print_every"] == 0
                and distutils.is_master()
                and not self.is_hpo
            ):
                log_str = [
                    "{}: {:.2e}".format(k, v) for k, v in log_dict.items()
                ]
                logging.info(", ".join(log_str))
                self.metrics = {}

            if self.logger is not None:
                self.logger.log(
                    log_dict,
                    step=self.step,
                    split="train",
                )

            if (
                checkpoint_every != -1
                and self.step % checkpoint_every == 0
            ):
                self.save(
                    checkpoint_file="checkpoint.pt", training_state=True
                )

            # Evaluate on val set every `eval_every` iterations.
            if self.step % eval_every == 0:
                if self.val_loader is not None:
                    val_metrics = self.validate(
                        split="val",
                        disable_tqdm=disable_eval_tqdm,
                    )
                    self.update_best(
                        primary_metric,
                        val_metrics,
                        disable_eval_tqdm=disable_eval_tqdm,
                    )
                    if self.is_hpo:
                        self.hpo_update(
                            self.epoch,
                            self.step,
                            self.metrics,
                            val_metrics,
                        )

                if self.config["task"].get("eval_relaxations", False):
                    if "relax_dataset" not in self.config["task"]:
                        logging.warning(
                            "Cannot evaluate relaxations, relax_dataset not specified"
                        )
                    else:
                        self.run_relaxations()

            if self.scheduler.scheduler_type == "ReduceLROnPlateau":
                if self.step % eval_every == 0:
                    self.scheduler.step(
                        metrics=val_metrics[primary_metric]["metric"],
                    )
            else:
                self.scheduler.step()

        torch.cuda.empty_cache()

        if checkpoint_every == -1:
            self.save(checkpoint_file="checkpoint.pt", training_state=True)

    self.train_dataset.close_db()
    if self.config.get("val_dataset", False):
        self.val_dataset.close_db()
    if self.config.get("test_dataset", False):
        self.test_dataset.close_db()

"""Override students train method"""

student_trainer.train = train.__get__(student_trainer, ForcesTrainer)

"""Now student_trainer's train method is the one with the KD loss included"""

student_trainer.train(kd_labels=teacher_pretrained_trainer.predict(teacher_pretrained_trainer.train_loader))